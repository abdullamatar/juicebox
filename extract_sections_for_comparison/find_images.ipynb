{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import match_template\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from imutils.object_detection import non_max_suppression # pip install imutils\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "pytesseract.image_to_string(Image.open('./A067/A067_header.bmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sections(reference_image,multi_up_image, output_img_path,threshold=0.75,saveit=False):\n",
    "\n",
    "    reference_gray = cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB)\n",
    "    multi_up_gray = cv2.cvtColor(multi_up_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    result = cv2.matchTemplate(multi_up_gray, reference_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    print(f\"{result.shape} total results found...\")\n",
    "\n",
    "    # threshold = 0.75  # Adjust this threshold as needed\n",
    "    loc = np.where(result >= threshold)\n",
    "\n",
    "    # Perform non-maximum suppression.\n",
    "    # template_h, template_w = reference_gray.shape[:2]\n",
    "    # rects = []\n",
    "    # for (x, y) in zip(loc[0], loc[1]):\n",
    "    #     rects.append((x, y, x + template_w, y + template_h))\n",
    "    # pick = non_max_suppression(np.array(rects))\n",
    "\n",
    "    # Define a function to remove duplicates within a specified distance (tolerance)\n",
    "    def remove_duplicates(points, tolerance, horizontal_tolerance):\n",
    "        unique_points = []\n",
    "        unique_indices = []\n",
    "        for i, (x, y) in enumerate(points):\n",
    "            is_unique = True\n",
    "            for j, (x_other, y_other) in enumerate(unique_points):\n",
    "                if abs(x - x_other) < horizontal_tolerance:\n",
    "                    is_unique = False\n",
    "                    break\n",
    "                distance = np.sqrt((x - x_other) ** 2 + (y - y_other) ** 2)\n",
    "                if distance <= tolerance:\n",
    "                    is_unique = False\n",
    "                    break\n",
    "            if is_unique:\n",
    "                unique_points.append((x, y))\n",
    "                unique_indices.append(i)\n",
    "        \n",
    "        return np.array(unique_points), np.array(unique_indices)\n",
    "\n",
    "    x, y = loc\n",
    "    print(f\"{len(x)} total occurrences found...\")\n",
    "\n",
    "    tolerance = 10  # Adjust this value as needed\n",
    "    horizontal_tolerance = reference_image.shape[0]//2\n",
    "    unique_loc, unique_indices = remove_duplicates(np.column_stack((x, y)), tolerance, horizontal_tolerance)\n",
    "    print(f\"{len(unique_indices)} unique found...\")\n",
    "\n",
    "    matched_sections = []\n",
    "    bb = deepcopy(multi_up_image)\n",
    "    for pt in unique_loc:\n",
    "        tl=(0,pt[0])\n",
    "        br=(multi_up_image.shape[1], pt[0] + reference_image.shape[0])\n",
    "        bb = cv2.rectangle(bb, tl, br, (0, 0, 255), 3)\n",
    "        matched_sections.append(multi_up_image[tl[1]:br[1],tl[0]:br[0]] )\n",
    "\n",
    "    # cv2.imshow(\"BB\", cv2.resize(bb, None, fx=0.15, fy=0.15))\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    if (saveit):\n",
    "        for i, matched_img in enumerate(matched_sections):\n",
    "            # if matched_img.size != 0:\n",
    "            cv2.imwrite(f\"{output_img_path}/{i}.jpg\", matched_img)\n",
    "\n",
    "    return result, bb, matched_sections, loc, unique_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5456, 1653) total results found...\n",
      "245 total occurrences found...\n",
      "6 unique found...\n"
     ]
    }
   ],
   "source": [
    "ref = '67'\n",
    "reference_image = cv2.imread(f'./A0{ref}/SA-A0{ref}.jpg', cv2.IMREAD_COLOR)\n",
    "multi_up_image = cv2.imread(\"multi_up.bmp\", cv2.IMREAD_COLOR) #f'./A0{ref}/A0{ref}_0.bmp'\n",
    "reference_image = cv2.resize(reference_image, (830, 1073))\n",
    "\n",
    "r,b,m,l,u = generate_sections(reference_image, multi_up_image, f'./A0{ref}',threshold=0.8,saveit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7,  692],\n",
       "       [1097,    2],\n",
       "       [2194,  141],\n",
       "       [3264,  279],\n",
       "       [4355,  417],\n",
       "       [5455,  554]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
